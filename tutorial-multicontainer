<Multi-Container Environment>
How to Dockerize applications which rely on different services to run such as 
web apps that require a database. In particular, how you can run and manage 
multi-container environments.



# <SF Food Trucks>
The app's backend is written in Python (Flask) and for search it uses 
Elasticsearch.

- Clone the repository
(e.g., $ git clone https://github.com/prakhar1989/FoodTrucks)

- The "flask-app" folder contains the Python application, while the "utils" 
folder has some utilities to load the data into Elasticsearch.

- The application consists of a Flask backend server and an Elasticsearch 
service. A natural way to split this app would be to have two containers - 
1. One running the Flask process 
2. Another running the Elasticsearch (ES) process.

- The Flask container is already built in the repository.

- For Elasticsearch, you can find something on the hub.
(e.g., $ docker search elasticsearch)

- Pull the image (Elastic, the company behind Elasticsearch maintains its own 
registry for Elastic products. It's recommended to use the images from that 
registry if you plan to use Elasticsearch - https://www.docker.elastic.co/)
(e.g., docker pull docker.elastic.co/elasticsearch/elasticsearch:6.3.2)

- Run it in development mode by specifying ports and setting an environment 
variable that configures the Elasticsearch cluster ro run as a single-node.
(e.g., $ docker run -d --name es -p 9200:9200 -p 9300:9300 -e "discovery.type=
single-node" docker.elastic.co/elasticsearch/elasticsearch:6.3.2)
(--name es: to give your container a name which makes it easy to use in 
subsequent commands)

- Once the container is started, you can see the logs by running 
"$ docker container logs" with the container name (or ID) to inspect the logs.
($ docker container ls) - to see a list of containers you have
($ docker container logs es)

- See if you can send a request to the ELasticsearch container.
User the 9200 port to send a cURL request to the container.
(* curl is a command line tool to transfer data to or from a server, using any 
of the supported protocols (HTTP, FTP, IMAP, POP3, SCP, SFTP, SMTP, TFTP, 
TELNET, LDAP or FILE...)
(e.g., $ curl 0.0.0.0:9200)

- Now you have to create a Docker Image of the Flask app. You can create a 
Docker Image with a Dockerfile. Go to FoodTrucks folder ($ cd FoodTrucks) and 
you can find the Dockerfile.

(Dockerfile in the previous tutorial)
-----------------------------------------------------
# specify your base image
FROM python:3

# set a directory for the app
WORKDIR /usr/src/app

# copy all the files to the container
COPY . .

# install dependencies
RUN pip install --no-cache-dir -r requirements.txt

# define the port number the container should expose
EXPOSE 5000

# run the command
CMD ["python", "./app.py"]
-----------------------------------------------------

* apart from installing Python dependencies via pip, you want your application 
to also generate your minified Javascript file for production. For this, we'll 
require Nodejs. Since you need a custom build step, we'll start from the ubuntu 
base image to build your Dockerfile from scratch.

(Dockerfile)
---------------------------------------------------------
# specify your base image
FROM ubuntu:latest

LABEL maintainer="Prakhar Srivastav <prakhar@prakhar.me>"

# install system-wide deps for python and node
RUN apt-get -yqq update
RUN apt-get -yqq install python-pip python-dev curl gnupg
RUN curl -sL https://deb.nodesource.com/setup_10.x | bash
RUN apt-get install -yq nodejs

# copy your application code
ADD flask-app /opt/flask-app
WORKDIR /opt/flask-app

# fetch app specific deps (install dependencies)
RUN npm install
RUN npm run build
RUN pip install -r requirements.txt

# define the port number the container should expose
EXPOSE 5000

# run the command
CMD [ "python", "./app.py" ]
---------------------------------------------------------

* If you find that an existing image doesn't cater to your needs, feel free to 
start from another base image on DockerHub and tweak it yourself.

New things:
1. Use the package manager apt-get to install the dependencies namely Python and 
Node.
2. The yqq flag is used to suppress output and assumes "Yes" to all prompts.
3. The ADD command to copy your application into a new volume in the container 
- /opt/flask-app. This is where your code will reside. Yiy also set this as your 
working directory, so that the following commands will be run in the context of 
this location. Now that your system-wide dependencies are installed, you get 
around to installing app-specific ones. First off you tackle Node by installing 
the packages from npm and running the build command as defined in your 
package.json file. You finish the file off by installing the Python packages, 
exposing the port and defining the CMD to run as you did in the last section.

* You are supposed to make a Docker Image that takes care of the Python 
application (the "flask-app" folder) and Elasticsearch(the "utils" folder) -> 
therefore, the Dockerfile needs to be placed in the context of FoodTrucks that 
contains both folders.

- In the same directory ($ cd FoodTrucks), command docker build
(e.g., $ docker build -t mrki102/foodtrucks-web .)

- See if your image shows
(e.g., $ docker images)

- Run the image to see if it actually works
(e.g., $ docker run -P --rm mrki102/foodtrucks-web)

- Confirm that the flask app is not able to run since it was unable to connect 
to Elasticsearch. In the following part, you will get to know how to tell one 
container about the other container and get them to talk to each other.



# <Docker Network>

- See what container do you have
($ docker container ls)

- Confirm that the "docker.elastic.co/elasticsearch/..." container is running.
The container is running on "0.0.0.0:9200 port". Meaning that it should be able 
to connect and talk to ES if you can tell your Flask app to connect to this URL.

- Go to ($ cd FoodTrucks/flask-app) and open "app.py" On the line 8, you can 
find "es = Elasticsearch(host='es')". This is the details that define the 
connection.

- To make this work, you need to tell the Flask container that the ES container 
is running on "0.0.0.0" host (the port by default is "9200"). But this is wrong.
"0.0.0.0" is the IP to access ES container from the host machine (i.e., from 
your laptop). Another container will not be able to access this on the same IP 
address.

- See all Network IDs and find the ID with the name of "bridge". That is the 
network in whcih containers are run by default. Meaning that when the ES 
container is running, it is in this bridge network.
(e.g., $ docker network ls)

- Inspect the network to validate this. confirm the "es" container is listed 
under the "Container" section in the output. What you can also see is the IP 
address. This container has been allotted - "172.17.0.2".
(e.g., $ docker network inspect bridge)

- Find out to see whether or not the IP address, "172.17.0.2", is what you are 
looking for by trying to access this IP while running your flask container.
(e.g., $ docker run -it --rm mrki102/foodtrucks-web bash) (then type this 
...-app#: curl 172.17.0.2:9200) "bash" is to start the container in the 
interactive mode with the bash process. Once you do this, you can if you can 
indeed talk to ES on "172.17.0.2:9200".

- Escape from there
(e.g., .../flask-app# exit)

- You still have to figure out two problems.
1. How do you tell the Flask container that "es" hostname stands for 
"172.17.0.2:9200" or some other IP since the IP address can change?
2. Since the bridge network is shared by every container by default, this 
approach is not secure. How do you isolate your network?

- Docker allows you to define your own networks while keep them isolated using 
the "docker network" command. Create a user-defined network with the command.
(e.g., $ docker network create foodtrucks-net)

- Confirm the network that you just created ("foodtrucks-net")
(e.g., $ docker network ls)

- Stop and remove the existing ES contianer that has been running in the default 
bridge network.
(e.g., $ docker container stop es > $ docker container rm es)

- Now you can relaunch both containers (Elasticsearch, mrki102/foodtrucks-web) 
inside this network using the "--net" flag. 
(e.g., $ docker run -d --name es --net foodtrucks-net -p 9200:9200 -p 9300:9300 
-e "discovery.type=single-node" docker.elastic.co/elasticsearch/
elasticsearch:6.3.2)

- Inspect the "foodtrucks-net" to see if the "es" container is running inside 
the "foodtrucks-net" bridge network.
(e.g., $ docker network inspect foodtrucks-net)

- Try what heppens when you launch "mrki102/foodtrucks-web" in the 
"foodtrucks-net" network. (It works!)
(e.g., $ docker run -it --rm --net foodtrucks-net mrki102/foodtrucks-web bash)
(.../flask-app# curl es:9200)
(.../flask-app# ls)
(.../flask-app# python app.py) - You can confirm the message that the app is 
running on "http://0.0.0.0:5000/". However, you can not access it with the 
browser because it is currently using the development server in a production 
environment.

- Stop and remove the "mrki102/foodtrucks-web" container and run it again.
(e.g., $ docker run -d --net foodtrucks-net -p 5000:5000 --name foodtrucks-web 
mrki102/foodtrucks-web)

- Now you can access "http://0.0.0.0:5000/" via browser.

* In summary, you can run this multi-container environment app with the 
following script. (setup-docker.sh)
--------------------------------------------------------------------------------
# build the flask container
docker build -t prakhar1989/foodtrucks-web .

# create the network
docker network create foodtrucks-net

# start the ES(Elasticsearch) container
docker run -d --name es --net foodtrucks-net -p 9200:9200 -p 9300:9300 -e 
"discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:6.3.2

# start the flask app container
docker run -d --net foodtrucks-net -p 5000:5000 --name foodtrucks-web 
prakhar1989/foodtrucks-web
--------------------------------------------------------------------------------

You can get a whole app running with just one command (./setup-docker.sh)
-----------------------------------------------------
$ git clone https://github.com/prakhar1989/FoodTrucks
$ cd FoodTrucks
$ ./setup-docker.sh
-----------------------------------------------------



# <Docker Compose>
Compose is a tool that is used for defining and running multi-container Docker 
apps in an easy way. It provides a configuration file called 
"docker-compose.yml" taht can be used to bring up an application and the suite 
of services it depends on with just one command.

- See if you can create a "docker-compose.yml" for your SF-Foodtrucks app and 
evaluate whether Docker Compose lives up to its promise.

- Install Docker Compose.
(e.g., $ pip install docker-compose)

- Check the version of Docker Compose
(e.g., $ docker-compose --version)

* If you failed to install Docker Compose
- 1. Download the Docker Compose binary into the /usr/local/bin directory with 
the following curl command.
(e.g., $ sudo curl -L "https://github.com/docker/compose/releases/download/
1.23.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose)
- 2. Once the download is complete, apply executable permissions to the Compose 
binary.
(e.g., $ sudo chmod +x /usr/local/bin/docker-compose)
- 3. Verify the installation by running the following command which will display 
the Compose version.
(e.g., $ docker-compose --version)
(Output: docker-compose version 1.23.1, build b02f1306)

- Now that Docker Compose is installed, you can create "docker-compose.yml" in 
the directory ($ cd FoodTrucks).
(docker-compose.yml)
------------------------------------------------------------------
version: "3"
services:
    es:
        image: docker.elastic.co/elasticsearch/elasticsearch:6.3.2
        container_name: es
        environment:
            - discovery.type=single-node
        ports:
            - 9200:9200
        volumes:
            - esdata1:/usr/share/elasticsearch/data
    web:
        image: mrki102/foodtrucks-web
        command: python app.py
        depends_on:
            - es
        ports:
            - 5000:5000
        volumes:
            - ./flask-app:/opt/flask-app
volumes:
    esdata1:
        driver: local
------------------------------------------------------------------
At the parent level, you define the names of your services "es" and "web".
You can add additional parameters out of which image is required for each 
service that Docker needs to run. You provide more information about the 
container with "command" and "ports". The "volumes" parameter specifies a mount 
point in your web container where the code will reside. This is purely optional 
and is useful if you need access to logs etc. You also add volumes for the "es" 
container so that the data you load persists between restarts. You also specify 
"depends_on", which tells docker to start the "es" container before web. 

* You must be inside the directory with the "docker-compose.yml" file in order 
to execute most Compose commands.

- Before have "docker-compose" in action, make sure that the ports and names are 
free by turning off the Flask and ES containers if they are still running.
(e.g., $ docker stop es foodtrucks-web)
(e.g., $ docker rm foodtrucks-web es)

- And also push your mrki102/foodtrucks-web to DockerHub. (Because you changed 
the Docker image name to "mrki102/foodtrucks-web", the corresponding repo should 
be found on DockerHub.)
(e.g., $ docker login)
(e.g., $ docker push mrki102/foodtrucks-web)

- Check your published image on DockerHub
(https://hub.docker.com/repository/docker/mrki102/foodtrucks-web)

- Now you can run "docker-compose up" at ($ cd FoodTrucks).
(e.g., $ docker-compose up)

- Head over to the IP to see your app live (http://0.0.0.0:5000/)
> Just a few lines of configuration and you have two Docker containers running 
successfully in unison.

- Stop the services and re-run in detached mode.
(e.g., $ docker-compose up -d)

- Confirm the currently running docker-compose services
(e.g., $ docker-compose ps)

- Names are automatically created by Docker Compose. But does Docker Compose 
also create the network automatically? You can find out.

- First, stop the services from running. (Data volumes are set in the 
"docker-compose.yml" file, so it's possible to start the cluster again with the 
same data using docker-compose up.) Destroy the cluster and the data voluems.
(e.g., $ docker-compose down -v)

- Also remove the "foodtrucks" network you created last time.
(e.g., $ docker network rm foodtrucks-net)

- Now that you have a clean slate, re-run your services and see if Docker 
Compose works even when there is no user-defined bridge network.
(e.g., $ docker-compose up -d)

- Check to see if the cluster service containers were created.
(e.g., $ docker container ls / $ docker ps)

- Check to See if any netowrks were created.
(e.g., $ docker network ls)

- You can confirm that Docker Compose went ahead and created a new network 
called "foodtrucks_default" and attached both the new services in that network 
so that each of these are discoverable to the other. (Each container for a 
service joins the default network and is both reachable by other containers on 
that network, and discoverable by them at a hostname identical to the container 
name.)
(e.g., $ docker network inspect foodtrucks_default)


# <Development Workflow>

